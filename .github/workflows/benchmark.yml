name: Benchmark

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    # Run benchmarks daily at 2 AM UTC
    - cron: "0 2 * * *"
  workflow_dispatch:
    inputs:
      benchmark_filter:
        description: "Benchmark filter (e.g., SearchBenchmarks)"
        required: false
        default: ""

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run-benchmark:
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch' || github.event_name == 'pull_request'
    runs-on: ubuntu-22.04 # 4 cores, 16GB RAM, consistent specs
    permissions:
      contents: write  # Need write for gh-pages push
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Need full history for ASV

      - name: Checkout gh-pages branch for benchmark history
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          path: gh-pages-checkout
        continue-on-error: true  # First run won't have gh-pages yet

      - name: Restore previous benchmark results from gh-pages
        run: |
          if [ -d "gh-pages-checkout/benchmarks/.asv" ]; then
            echo "Restoring benchmark history from gh-pages..."
            mkdir -p .asv
            cp -r gh-pages-checkout/benchmarks/.asv/* .asv/ || true
            echo "Restored benchmark history"
            ls -la .asv/results/ || echo "No previous results found"
          else
            echo "No previous benchmark history found (this may be the first run)"
          fi

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v2

      - name: Install ASV
        run: uv tool install asv

      - name: Configure ASV for PR context
        if: github.event_name == 'pull_request'
        run: |
          # For PRs, only track the current HEAD to avoid 'main' branch not found errors
          python -c "
          import json
          with open('asv.conf.json', 'r') as f:
              config = json.load(f)
          config['branches'] = ['HEAD']
          with open('asv.conf.json', 'w') as f:
              json.dump(config, f, indent=4)
          print('ASV configured for PR context - tracking only HEAD')
          "

      - name: Configure ASV for main branch
        if: github.event_name != 'pull_request'
        run: |
          # For main branch and other contexts, track main and HEAD
          python -c "
          import json
          with open('asv.conf.json', 'r') as f:
              config = json.load(f)
          config['branches'] = ['main', 'HEAD']
          with open('asv.conf.json', 'w') as f:
              json.dump(config, f, indent=4)
          print('ASV configured for main branch context - tracking main and HEAD')
          "

      - name: Setup ASV machine
        env:
          IMAS_MCP_EMBEDDING_MODEL: all-MiniLM-L6-v2
          HF_HUB_DISABLE_SYMLINKS_WARNING: 1
        run: |
          # Get actual system specifications from the runner
          CPU_INFO=$(lscpu | grep "Model name" | cut -d: -f2 | sed 's/^[ \t]*//' | head -1)
          CPU_COUNT=$(nproc)
          RAM_MB=$(free -m | grep "Mem:" | awk '{print $2}')
          RAM_GB=$((RAM_MB / 1024))
          ARCH=$(uname -m)

          # Get OS details
          OS_VERSION=$(lsb_release -ds 2>/dev/null | tr -d '"' || echo "Unknown")

          # Create machine name from key specs to detect hardware changes
          # Format: {arch}-{cores}c-{ram}gb
          MACHINE_NAME="${ARCH}-${CPU_COUNT}c-${RAM_GB}gb"
          echo "Machine name: $MACHINE_NAME"

          # Configure machine with detected specs
          asv machine \
            --machine "$MACHINE_NAME" \
            --os "$OS_VERSION" \
            --arch "$ARCH" \
            --cpu "$CPU_INFO" \
            --num_cpu "$CPU_COUNT" \
            --ram "${RAM_GB}GB" \
            --yes

          # Store machine name for benchmark run
          echo "MACHINE_NAME=$MACHINE_NAME" >> $GITHUB_ENV

      - name: Run benchmarks
        env:
          IMAS_MCP_EMBEDDING_MODEL: all-MiniLM-L6-v2
          HF_HUB_DISABLE_SYMLINKS_WARNING: 1
        run: |
          # Run benchmarks
          if [ -n "${{ github.event.inputs.benchmark_filter }}" ]; then
            asv run --python=3.12 --machine "$MACHINE_NAME" -b "${{ github.event.inputs.benchmark_filter }}" --verbose
          else
            asv run --python=3.12 --machine "$MACHINE_NAME" HEAD^! --verbose
          fi

      - name: Show benchmark results on failure
        if: failure()
        run: |
          echo "Benchmark run failed. Checking for logs..."
          find .asv -name "*.log" -exec echo "=== {} ===" \; -exec cat {} \; || true
          echo "Checking ASV results directory..."
          ls -la .asv/ || true
          echo "Checking if schema files exist..."
          ls -la imas_mcp/resources/schemas/ || true

      - name: Generate HTML report
        run: asv publish

      - name: Setup Pages
        if: github.ref == 'refs/heads/main'
        uses: actions/configure-pages@v5

      - name: Prepare benchmarks for deployment
        if: github.ref == 'refs/heads/main'
        run: |
          # Create benchmark deployment directory with full ASV data for history persistence
          mkdir -p deploy/benchmarks
          cp -r .asv/html/* deploy/benchmarks/
          
          # Copy ASV results and machine config for next run to restore
          mkdir -p deploy/benchmarks/.asv
          cp -r .asv/results deploy/benchmarks/.asv/
          cp -r .asv/machine.json deploy/benchmarks/.asv/ || true

          # Create a simple landing page for benchmarks
          cat > deploy/index.html << 'EOF'
          <!DOCTYPE html>
          <html lang="en">
          <head>
              <meta charset="UTF-8">
              <meta name="viewport" content="width=device-width, initial-scale=1.0">
              <title>IMAS MCP Benchmarks</title>
              <style>
                  body { font-family: system-ui, -apple-system, sans-serif; max-width: 800px; margin: 50px auto; padding: 20px; }
                  h1 { color: #333; }
                  a { color: #0366d6; text-decoration: none; }
                  a:hover { text-decoration: underline; }
              </style>
          </head>
          <body>
              <h1>IMAS MCP Performance Benchmarks</h1>
              <p>Historical performance tracking using Airspeed Velocity (ASV)</p>
              <p><a href="./benchmarks/">ðŸ“Š View Benchmark Reports</a></p>
          </body>
          </html>
          EOF

      - name: Upload Pages artifact
        if: github.ref == 'refs/heads/main'
        uses: actions/upload-pages-artifact@v3
        with:
          path: deploy

      - name: Deploy to GitHub Pages
        if: github.ref == 'refs/heads/main'
        id: deployment
        uses: actions/deploy-pages@v4
