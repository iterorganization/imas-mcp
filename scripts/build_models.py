#!/usr/bin/env python3
"""
Build Pydantic models from LinkML ontology schemas.

Source: imas_codex/ontology/discovery/*.yaml
Output: imas_codex/discovery/models/*.py

To regenerate:
    uv run build-models --force
"""

import logging
import subprocess
import sys
from pathlib import Path

import click


def get_project_root() -> Path:
    """Get the project root directory."""
    return Path(__file__).parent.parent


def get_ontology_dir() -> Path:
    """Get the ontology directory containing LinkML schemas."""
    return get_project_root() / "imas_codex" / "ontology" / "discovery"


def get_discovery_dir() -> Path:
    """Get the discovery module directory."""
    return get_project_root() / "imas_codex" / "discovery"


@click.command()
@click.option("--verbose", "-v", is_flag=True, help="Enable verbose logging output")
@click.option("--quiet", "-q", is_flag=True, help="Suppress all logging except errors")
@click.option(
    "--force", "-f", is_flag=True, help="Force rebuild even if files already exist"
)
@click.option(
    "--dry-run",
    is_flag=True,
    help="Show what would be generated without writing files",
)
def build_models(
    verbose: bool,
    quiet: bool,
    force: bool,
    dry_run: bool,
) -> int:
    """Generate Pydantic models from LinkML discovery schema.

    This command uses linkml's gen-pydantic generator to create Python models
    from the discovery/*.yaml schemas. The generated code is written to
    imas_codex/discovery/models/*.py.

    Examples:
        build-discovery-models              # Generate models
        build-discovery-models -v           # Verbose output
        build-discovery-models --dry-run    # Preview without writing
        build-discovery-models -f           # Force regeneration
    """
    # Set up logging level
    if quiet:
        log_level = logging.ERROR
    elif verbose:
        log_level = logging.DEBUG
    else:
        log_level = logging.INFO

    logging.basicConfig(
        level=log_level, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    logger = logging.getLogger(__name__)

    try:
        ontology_dir = get_ontology_dir()
        discovery_dir = get_discovery_dir()
        models_dir = discovery_dir / "models"

        # Ensure models directory exists
        models_dir.mkdir(parents=True, exist_ok=True)

        # Schemas to process
        schemas = ["data", "environment", "filesystem", "tools"]

        # Track generated classes for __init__.py
        generated_modules = []

        for schema_name in schemas:
            schema_file = ontology_dir / f"{schema_name}.yaml"
            output_file = models_dir / f"{schema_name}.py"

            # Validate schema exists
            if not schema_file.exists():
                logger.error(f"Schema file not found: {schema_file}")
                continue

            # Check if output already exists
            if output_file.exists() and not force:
                logger.info(f"Model {schema_name} already exists at {output_file}")
                generated_modules.append(schema_name)
                continue

            logger.info(f"Generating Pydantic models from {schema_file}")

            if dry_run:
                click.echo(f"Would generate: {output_file}")
                continue

            # Run gen-pydantic
            cmd = [
                "gen-pydantic",
                str(schema_file),
            ]

            logger.debug(f"Running command: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=False,
            )

            if result.returncode != 0:
                logger.error(f"gen-pydantic failed for {schema_name}: {result.stderr}")
                click.echo(
                    f"Error: gen-pydantic failed for {schema_name}:\n{result.stderr}",
                    err=True,
                )
                return 1

            # Add header comment to generated code
            header = f'''"""
Discovery Engine Pydantic Models - {schema_name.capitalize()}.

AUTO-GENERATED from imas_codex/ontology/discovery/{schema_name}.yaml
DO NOT EDIT THIS FILE DIRECTLY - edit the LinkML schema instead.

To regenerate:
    uv run build-models --force
"""

'''
            generated_code = header + result.stdout

            # Write output
            output_file.write_text(generated_code)
            logger.info(f"Generated models written to {output_file}")
            generated_modules.append(schema_name)

        if dry_run:
            return 0

        # Generate __init__.py
        init_file = models_dir / "__init__.py"
        init_content = [
            '"""',
            "Discovery Engine Pydantic Models.",
            "",
            "AUTO-GENERATED - DO NOT EDIT",
            '"""',
            "",
        ]

        # We need to know which classes to export.
        # For now, we'll export everything from the modules.
        # A better approach would be to parse the generated files or schemas,
        # but star imports are easier for this build script.

        # However, to avoid pollution, let's try to be specific if we can.
        # But since we don't know the class names easily without parsing,
        # we will use explicit imports based on known artifact names if possible,
        # or just import the modules.

        # The finish.py expects:
        # from imas_codex.discovery.models import DataArtifact, EnvironmentArtifact, FilesystemArtifact, ToolsArtifact

        # Let's hardcode the known artifacts for now to ensure they are exported.
        # This is a bit brittle but matches the current requirement.

        init_content.append("from .data import DataArtifact")
        init_content.append("from .environment import EnvironmentArtifact")
        init_content.append("from .filesystem import FilesystemArtifact")
        init_content.append("from .tools import ToolsArtifact")
        init_content.append("")
        init_content.append("__all__ = [")
        init_content.append('    "DataArtifact",')
        init_content.append('    "EnvironmentArtifact",')
        init_content.append('    "FilesystemArtifact",')
        init_content.append('    "ToolsArtifact",')
        init_content.append("]")
        init_content.append("")

        init_file.write_text("\n".join(init_content))
        logger.info(f"Generated __init__.py at {init_file}")

        return 0

    except Exception as e:
        logger.error(f"Error generating models: {e}")
        if verbose:
            logger.exception("Full traceback:")
        click.echo(f"Error: {e}", err=True)
        return 1


if __name__ == "__main__":
    sys.exit(build_models())
